{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Torch, and Personalised Scripts, using Conda env ml_adi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as td\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "from scripts.unet_model import *\n",
    "from scripts.indices import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = '/application/pi/Desktop/all imp data/Unet_training/images/'\n",
    "mask_dir = '/application/pi/Desktop/all imp data/Unet_training/masks/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlaneDataSet(td.Dataset):\n",
    "    \n",
    "    def __init__(self, image_path, mask_path):\n",
    "        import os\n",
    "        \n",
    "        self.image_path = image_path\n",
    "        \n",
    "        self.mask_path = mask_path\n",
    "        c = os.listdir(mask_path)\n",
    "        c.remove('.ipynb_checkpoints')\n",
    "        self.filenames = c\n",
    "        \n",
    "        self.filenames \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        #Load the image\n",
    "        img_path = os.path.join(self.image_path, self.filenames[index])\n",
    "        image =  np.load(img_path)\n",
    "        \n",
    "        # Make Indices\n",
    "        image_np = allIndices(image)\n",
    "        \n",
    "        # Normalize\n",
    "        image_np = normalize(image_np)\n",
    "        \n",
    "        # Convert to a tensor\n",
    "        image_tensor = torch.Tensor(image_np)\n",
    "        \n",
    "        # Now doing operations to mask\n",
    "        mask_path = os.path.join(self.mask_path, self.filenames[index])\n",
    "        mask =  np.load(mask_path)\n",
    "        mask_np = np.expand_dims(mask, axis=0)\n",
    "        mask_tensor = torch.Tensor(mask_np)\n",
    "        \n",
    "        return(image_tensor, mask_tensor)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(image_path, mask_path):\n",
    "\n",
    "    # Load all of the images, transforming them\n",
    "    dataset = PlaneDataSet(image_path , mask_path)\n",
    "    \n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "    \n",
    "    # define the loaders for the image data\n",
    "    image_loader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=4,\n",
    "        num_workers=0,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=4,\n",
    "        num_workers=0,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=4,\n",
    "        num_workers=0,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    return image_loader, train_loader, test_loader\n",
    "\n",
    "image_loader, train_loader, test_loader = load_data(image_dir, mask_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Size :  384\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Size : \",len(train_loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Size :  96\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Size : \",len(test_loader.dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Unet and Training for 1 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, data_loader, optimizer, epoch):\n",
    "    \n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    train_loss = 0\n",
    "    print(\"Epoch:\", epoch, \"...\")\n",
    "    # Process the images in batches\n",
    "    for batch_idx, (data, target) in enumerate(data_loader):\n",
    "        \n",
    "        \n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # Reset the optimizer\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Push the data forward through the model layers\n",
    "        output = model(data)\n",
    "        \n",
    "        # Get the loss\n",
    "        loss = loss_criteria(output, target)\n",
    "        \n",
    "        # Keep a running total\n",
    "        train_loss += loss.item()\n",
    "        # Backpropagate\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print('loss =', loss.item(),' number',batch_idx)\n",
    "        \n",
    "    # return average loss for the epoch\n",
    "    avg_training_loss = train_loss / (batch_idx+1)\n",
    "    print(\"\\tTraining set: Average loss: {:.6f}\".format(avg_training_loss))\n",
    "    return avg_training_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cpu\n",
      "Epoch: 1 ...\n",
      "loss = 0.19982165098190308  number 0\n",
      "loss = 0.5076178312301636  number 1\n",
      "loss = 0.4586745500564575  number 2\n",
      "loss = 0.27822092175483704  number 3\n",
      "loss = 0.2773345708847046  number 4\n",
      "loss = 0.38744664192199707  number 5\n",
      "loss = 0.6527146100997925  number 6\n",
      "loss = 0.28363028168678284  number 7\n",
      "loss = 0.4228696823120117  number 8\n",
      "loss = 0.2910708785057068  number 9\n",
      "loss = 0.26123949885368347  number 10\n",
      "loss = 0.29255932569503784  number 11\n",
      "loss = 0.24882063269615173  number 12\n",
      "loss = 0.3866499960422516  number 13\n",
      "loss = 0.30259010195732117  number 14\n",
      "loss = 0.31181859970092773  number 15\n",
      "loss = 0.29163622856140137  number 16\n",
      "loss = 0.32704511284828186  number 17\n",
      "loss = 0.41978558897972107  number 18\n",
      "loss = 0.29814913868904114  number 19\n",
      "loss = 0.39684537053108215  number 20\n",
      "loss = 0.307110995054245  number 21\n",
      "loss = 0.2766311466693878  number 22\n",
      "loss = 0.21835224330425262  number 23\n",
      "loss = 0.28179851174354553  number 24\n",
      "loss = 0.302668035030365  number 25\n",
      "loss = 0.24552033841609955  number 26\n",
      "loss = 0.2774219512939453  number 27\n",
      "loss = 0.2840158939361572  number 28\n",
      "loss = 0.22193151712417603  number 29\n",
      "loss = 0.3478906750679016  number 30\n",
      "loss = 0.26596736907958984  number 31\n",
      "loss = 0.3158545196056366  number 32\n",
      "loss = 0.369019478559494  number 33\n",
      "loss = 0.28060388565063477  number 34\n",
      "loss = 0.291232705116272  number 35\n",
      "loss = 0.30048683285713196  number 36\n",
      "loss = 0.3507046699523926  number 37\n",
      "loss = 0.24511975049972534  number 38\n",
      "loss = 0.3243597149848938  number 39\n",
      "loss = 0.33267804980278015  number 40\n",
      "loss = 0.2454032003879547  number 41\n",
      "loss = 0.22885997593402863  number 42\n",
      "loss = 0.17000968754291534  number 43\n",
      "loss = 0.25364044308662415  number 44\n",
      "loss = 0.20087745785713196  number 45\n",
      "loss = 0.2669171690940857  number 46\n",
      "loss = 0.29594823718070984  number 47\n",
      "loss = 0.24148602783679962  number 48\n",
      "loss = 0.20978973805904388  number 49\n",
      "loss = 0.23774921894073486  number 50\n",
      "loss = 0.268725723028183  number 51\n",
      "loss = 0.18067437410354614  number 52\n",
      "loss = 0.20713621377944946  number 53\n",
      "loss = 0.24785974621772766  number 54\n",
      "loss = 0.19048437476158142  number 55\n",
      "loss = 0.1532038450241089  number 56\n",
      "loss = 0.2773926556110382  number 57\n",
      "loss = 0.20668983459472656  number 58\n",
      "loss = 0.1516898274421692  number 59\n",
      "loss = 0.2579904794692993  number 60\n",
      "loss = 0.22026437520980835  number 61\n",
      "loss = 0.27730050683021545  number 62\n",
      "loss = 0.21816347539424896  number 63\n",
      "loss = 0.17019079625606537  number 64\n",
      "loss = 0.22464466094970703  number 65\n",
      "loss = 0.19696243107318878  number 66\n",
      "loss = 0.18452084064483643  number 67\n",
      "loss = 0.19952857494354248  number 68\n",
      "loss = 0.1572992205619812  number 69\n",
      "loss = 0.2370474636554718  number 70\n",
      "loss = 0.2418479174375534  number 71\n",
      "loss = 0.259928822517395  number 72\n",
      "loss = 0.21420922875404358  number 73\n",
      "loss = 0.18711155652999878  number 74\n",
      "loss = 0.29239583015441895  number 75\n",
      "loss = 0.21676340699195862  number 76\n",
      "loss = 0.17195731401443481  number 77\n",
      "loss = 0.20744657516479492  number 78\n",
      "loss = 0.2823306918144226  number 79\n",
      "loss = 0.1851617991924286  number 80\n",
      "loss = 0.2847525179386139  number 81\n",
      "loss = 0.16864463686943054  number 82\n",
      "loss = 0.1761883795261383  number 83\n",
      "loss = 0.17764365673065186  number 84\n",
      "loss = 0.17469409108161926  number 85\n",
      "loss = 0.2462928593158722  number 86\n",
      "loss = 0.28263983130455017  number 87\n",
      "loss = 0.22600992023944855  number 88\n",
      "loss = 0.20290310680866241  number 89\n",
      "loss = 0.21796467900276184  number 90\n",
      "loss = 0.2319398820400238  number 91\n",
      "loss = 0.29371559619903564  number 92\n",
      "loss = 0.2525140643119812  number 93\n",
      "loss = 0.19410426914691925  number 94\n",
      "loss = 0.22795790433883667  number 95\n",
      "\tTraining set: Average loss: 0.263870\n"
     ]
    }
   ],
   "source": [
    "# Create a UNet model\n",
    "model = UNet(n_channels=20, n_classes = 1)\n",
    "\n",
    "# Use the best available device (GPU/CPU) for training\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# # Uncomment the below when training continued epochs\n",
    "model.load_state_dict(torch.load('/application/pi/unet_trained_with_indices.pt', map_location=device))\n",
    "\n",
    "# Specify the optimizer and  loss criteria\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=0.001)\n",
    "loss_criteria = nn.BCELoss()\n",
    "\n",
    "# Track metrics in these arrays\n",
    "epoch_nums = []\n",
    "training_loss = []\n",
    "\n",
    "epochs = 1\n",
    "print('Training on', device)\n",
    "for epoch in range(1, epochs + 1):\n",
    "        train_loss = train(model, device, train_loader, optimizer, epoch)\n",
    "        epoch_nums.append(epoch)\n",
    "        training_loss.append(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Torch Model\n",
    "torch.save(model.state_dict(), '/application/pi/unet_trained_with_indices.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = UNet(n_channels=20, n_classes = 1)\n",
    "model.load_state_dict(torch.load('/application/pi/unet_trained_with_indices.pt', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (inc): inconv(\n",
       "    (conv): double_conv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(20, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down1): down(\n",
       "    (mpconv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): double_conv(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down2): down(\n",
       "    (mpconv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): double_conv(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down3): down(\n",
       "    (mpconv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): double_conv(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down4): down(\n",
       "    (mpconv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): double_conv(\n",
       "        (conv): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up1): up(\n",
       "    (conv): double_conv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up2): up(\n",
       "    (conv): double_conv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up3): up(\n",
       "    (conv): double_conv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up4): up(\n",
       "    (conv): double_conv(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (outc): outconv(\n",
       "    (conv): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for batch_idx, (data, target) in enumerate(test_loader):\n",
    "    data1 = data\n",
    "    target1 = target\n",
    "    if batch_idx%4 ==0:\n",
    "        with torch.no_grad():\n",
    "            output = model(data1)\n",
    "        a=np.array(output[0])\n",
    "        b=np.array(target1[0])\n",
    "        \n",
    "        np.save('/application/pi/Desktop/all imp data/Unet testing/trial_image_'+str(i)+'.npy',a)\n",
    "        np.save('/application/pi/Desktop/all imp data/Unet testing/trial_mask_'+str(i)+'.npy',b)\n",
    "        i = i+1\n",
    "    print(batch_idx)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_adi",
   "language": "python",
   "name": "ml_adi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
