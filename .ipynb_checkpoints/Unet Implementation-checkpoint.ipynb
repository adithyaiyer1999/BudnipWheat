{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Torch, and Personalised Scripts, using Conda env ml_adi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as td\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "from scripts.unet_model import *\n",
    "from scripts.indices import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = '/application/pi/Desktop/all imp data/Unet_training/images/'\n",
    "mask_dir = '/application/pi/Desktop/all imp data/Unet_training/masks/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlaneDataSet(td.Dataset):\n",
    "    \n",
    "    def __init__(self, image_path, mask_path):\n",
    "        import os\n",
    "        \n",
    "        self.image_path = image_path\n",
    "        \n",
    "        self.mask_path = mask_path\n",
    "        c = os.listdir(mask_path)\n",
    "        c.remove('.ipynb_checkpoints')\n",
    "        self.filenames = c\n",
    "        \n",
    "        self.filenames \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        #Load the image\n",
    "        img_path = os.path.join(self.image_path, self.filenames[index])\n",
    "        image =  np.load(img_path)\n",
    "        \n",
    "        # Make Indices\n",
    "        image_np = allIndices(image)\n",
    "        \n",
    "        # Normalize\n",
    "        image_np = normalize(image_np)\n",
    "        \n",
    "        # Convert to a tensor\n",
    "        image_tensor = torch.Tensor(image_np)\n",
    "        \n",
    "        # Now doing operations to mask\n",
    "        mask_path = os.path.join(self.mask_path, self.filenames[index])\n",
    "        mask =  np.load(mask_path)\n",
    "        mask_np = np.expand_dims(mask, axis=0)\n",
    "        mask_tensor = torch.Tensor(mask_np)\n",
    "        \n",
    "        return(image_tensor, mask_tensor)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(image_path, mask_path):\n",
    "\n",
    "    # Load all of the images, transforming them\n",
    "    dataset = PlaneDataSet(image_path , mask_path)\n",
    "    index_chosen = [78,210,87,276,89,175,298,20,129,198,283,233,54,191,300,26,170,76,154,309,379,376,266,82,287,174,345,311,44,217,121,409,449,374,277,199,97,293,143,11,347,436,156,226,378,153,28,100,218,341,326,336,202,354,124,407,109,292,184,476,183,360,232,235,269,369,141,75,270,102,10,138,0,380,415,201,59,268,145,459,384,302,131,337,456,123,322,25,328,117,231,248,401,356,45,128]\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "    test_dataset1 = torch.utils.data.Subset(dataset,indices=index_chosen)\n",
    "\n",
    "    # define the loaders for the image data\n",
    "    image_loader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=4,\n",
    "        num_workers=0,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=4,\n",
    "        num_workers=0,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=4,\n",
    "        num_workers=0,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    test_loader1 = torch.utils.data.DataLoader(\n",
    "        test_dataset1,\n",
    "        batch_size=4,\n",
    "        num_workers=0,\n",
    "        shuffle=False,\n",
    "    )\n",
    "    return image_loader, train_loader, test_loader,test_loader1\n",
    "\n",
    "image_loader, train_loader, test_loader,test_loader1 = load_data(image_dir, mask_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Unet and Training for 1 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, data_loader, optimizer, epoch):\n",
    "    \n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    train_loss = 0\n",
    "    print(\"Epoch:\", epoch, \"...\")\n",
    "    # Process the images in batches\n",
    "    for batch_idx, (data, target) in enumerate(data_loader):\n",
    "        \n",
    "        \n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # Reset the optimizer\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Push the data forward through the model layers\n",
    "        output = model(data)\n",
    "        \n",
    "        # Get the loss\n",
    "        loss = loss_criteria(output, target)\n",
    "        \n",
    "        # Keep a running total\n",
    "        train_loss += loss.item()\n",
    "        # Backpropagate\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print('loss =', loss.item(),' number',batch_idx)\n",
    "        \n",
    "    # return average loss for the epoch\n",
    "    avg_training_loss = train_loss / (batch_idx+1)\n",
    "    print(\"\\tTraining set: Average loss: {:.6f}\".format(avg_training_loss))\n",
    "    return avg_training_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "# Create a UNet model\n",
    "model = UNet(n_channels=20, n_classes = 1)\n",
    "\n",
    "# Use the best available device (GPU/CPU) for training\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# # Uncomment the below when training continued epochs\n",
    "model.load_state_dict(torch.load('/application/pi/unet_trained_with_indices.pt', map_location=device))\n",
    "\n",
    "Specify the optimizer and  loss criteria\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=0.001)\n",
    "loss_criteria = nn.BCELoss()\n",
    "\n",
    "# Track metrics in these arrays\n",
    "epoch_nums = []\n",
    "training_loss = []\n",
    "\n",
    "epochs = 5\n",
    "print('Training on', device)\n",
    "for epoch in range(1, epochs + 1):\n",
    "        train_loss = train(model, device, train_loader, optimizer, epoch)\n",
    "        epoch_nums.append(epoch)\n",
    "        training_loss.append(train_loss)\n",
    "        \n",
    "torch.save(model.state_dict(), '/application/pi/unet_trained_with_indices.pt')\n",
    "\n",
    "model.eval()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for batch_idx, (data, target) in enumerate(test_loader1):\n",
    "    data1 = data\n",
    "    target1 = target\n",
    "    if batch_idx%1 ==0:\n",
    "        with torch.no_grad():\n",
    "            output = model(data1)\n",
    "        a=np.array(output[0])\n",
    "        b=np.array(target1[0])\n",
    "        \n",
    "        np.save('/application/pi/Desktop/all imp data/Unet testing/images/trial_0_'+str(i)+'.npy',a)\n",
    "        np.save('/application/pi/Desktop/all imp data/Unet testing/masks/trial_0_'+str(i)+'.npy',b)\n",
    "        \n",
    "        a=np.array(output[1])\n",
    "        b=np.array(target1[1])\n",
    "        \n",
    "        np.save('/application/pi/Desktop/all imp data/Unet testing/images/trial_1_'+str(i)+'.npy',a)\n",
    "        np.save('/application/pi/Desktop/all imp data/Unet testing/masks/trial_1_'+str(i)+'.npy',b)\n",
    "        \n",
    "        a=np.array(output[2])\n",
    "        b=np.array(target1[2])\n",
    "        \n",
    "        np.save('/application/pi/Desktop/all imp data/Unet testing/images/trial_2_'+str(i)+'.npy',a)\n",
    "        np.save('/application/pi/Desktop/all imp data/Unet testing/masks/trial_2_'+str(i)+'.npy',b)\n",
    "        \n",
    "        a=np.array(output[3])\n",
    "        b=np.array(target1[3])\n",
    "        \n",
    "        np.save('/application/pi/Desktop/all imp data/Unet testing/images/trial_3_'+str(i)+'.npy',a)\n",
    "        np.save('/application/pi/Desktop/all imp data/Unet testing/masks/trial_3_'+str(i)+'.npy',b)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        i = i+1\n",
    "    print(batch_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_adi",
   "language": "python",
   "name": "ml_adi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
